{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from tqdm import tqdm_notebook as timer\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "import sklearn.linear_model as lm\n",
    "import sklearn.metrics as mcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a set of features that include the following:\n",
    "- top 5 pageranks of the actors (five floating point values) in each movie.\n",
    "- if the director is one of the top 100 directors or not (101 boolean values).These\n",
    "are directors of the top 100 movies from the \"IMDb top 250\". \n",
    "\n",
    "You can also\n",
    "find a list of these movies in the movie_rating.txt file.\n",
    "train a regression model and predict the ratings of the 3 movies mentioned\n",
    "above. \n",
    "\n",
    "Specify the exact feature set you use and how you compute the numerical\n",
    "values for these features. Compute and state the goodness of fit for your\n",
    "regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get A,M from File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"pyfiles/A.pkl\") as afile, open(\"pyfiles/M.pkl\") as mfile:\n",
    "    A = pkl.load(afile)\n",
    "    M = pkl.load(mfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get PageRanks from File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "page_ranks = pd.read_csv(\"page_rank.txt\", sep=\"\\t\")\n",
    "page_ranks[\"Name\"] = page_ranks[\"Name\"].apply(string.rstrip)\n",
    "page_ranks = page_ranks.set_index(\"Name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find top 100 movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movies = pd.read_csv(\"data/top_250.txt\", sep=\"\\t\", header=None)\n",
    "top_100 = {movie : i for (i, movie) in enumerate( movies[0].values[1:100] )}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get movie ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratings = pd.read_csv(\"ratings.txt\", sep = \"\\t\", header = None, names=[\"Name\", \"Rating\"])\n",
    "ratings = ratings.set_index(\"Name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Match each movie to (director == top-100 director)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "D = {}\n",
    "\n",
    "printable = set(string.printable)\n",
    "\n",
    "def clean_string(s):\n",
    "    # Remove (*)\n",
    "    s = re.sub(r'\\([^0-9]+\\)', '', s)\n",
    "\n",
    "    # Remove {*}\n",
    "    s = re.sub(r'\\{.*\\}', '', s)\n",
    "    \n",
    "    # Remove multiple spaces\n",
    "    s = re.sub(r'\\s+', ' ', s)\n",
    "\n",
    "    # Strip spaces etc\n",
    "    s = s.lstrip()\n",
    "    s = s.rstrip()\n",
    "\n",
    "    return s\n",
    "\n",
    "all_movies = set( M.keys() )\n",
    "\n",
    "with open(\"data/director_movies.txt\") as f:\n",
    "    for line in timer(f, total = 389663, desc = \"directors\"):\n",
    "        line = filter(lambda x : x in printable, line.decode('latin1')).encode('ascii')\n",
    "        splits = line.split(\"\\t\\t\")\n",
    "        \n",
    "        dname = clean_string(splits[0])\n",
    "        movies = set( map(clean_string, splits[1:]) )\n",
    "        \n",
    "        # Filter out unwanted movies\n",
    "        movies = movies.intersection(all_movies)\n",
    "        \n",
    "        if movie in top_100:\n",
    "            D[movie] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find all movies where ratings are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "available_movies = set(M.keys()).intersection(ratings.index.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run a logistic regression using the features:\n",
    "1. Top 10 page ranks of actors\n",
    "2. Boolean indicating whether director was top 100 or not\n",
    "3. Number of instances where an actor has acted in top 100 movies\n",
    "4. Average page rank of actors in the movie\n",
    "5. Average rating of neighbors in the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def build_feature_vector(movie):\n",
    "    arr = [0] * 14\n",
    "    \n",
    "    prs = sorted( page_ranks.loc[ M[movie] ][\"PageRank\"], reverse=True)\n",
    "    neighbors = [m for a in M[movie] for m in A[a]]\n",
    "    \n",
    "    # Top 10 page ranks of actors\n",
    "    arr[:10] = top10_prs = prs[:10]\n",
    "    \n",
    "    # Boolean indicating whether director was top 100 or not\n",
    "    arr[10] = D.get(movie, 0)\n",
    "    \n",
    "    # Number of instances where an actor has acted in top 100 movies\n",
    "    arr[11] = sum( map(lambda x : x in top_100, neighbors) )\n",
    "    \n",
    "    # Average page rank of actors in the movie\n",
    "    arr[12] = np.mean( prs )\n",
    "    \n",
    "    # Average rating of neighbors in the graph\n",
    "    arr[13] = np.mean( ratings.loc[ neighbors ][\"Rating\"] )\n",
    "    \n",
    "    return( np.array( arr ) )\n",
    "\n",
    "feature_vec = np.vstack(map(build_feature_vector, timer(available_movies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_vec = ratings.loc[ available_movies ][\"Rating\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = lm.LinearRegression()\n",
    "\n",
    "lr.fit(feature_vec, target_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_movies = [\n",
    "    \"Batman v Superman: Dawn of Justice (2016)\",\n",
    "    \"Mission: Impossible III (2006)\",\n",
    "    \"Minions (2015)\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_vec = map(build_feature_vector, test_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run on 3 movies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.7661026 ,  6.6520514 ,  7.28253742])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.predict(test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted = lr.predict(feature_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goodness of fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72653928112780397"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcs.mean_absolute_error(target_vec, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87764049096049612"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcs.mean_squared_error(target_vec, predicted)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "widgets": {
   "state": {
    "2465fcff9def43ee92ba8f1a263edee7": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    },
    "fbdd8fcb8d4046aa808f793072428e6a": {
     "views": [
      {
       "cell_index": 11
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
