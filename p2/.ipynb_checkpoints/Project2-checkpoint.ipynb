{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm as pbar\n",
    "import numpy as np\n",
    "from itertools import islice\n",
    "import string\n",
    "from scipy.sparse import lil_matrix, csc_matrix\n",
    "from itertools import combinations\n",
    "from tqdm import tqdm_notebook as timer\n",
    "from scipy.misc import comb\n",
    "import re\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the graph\n",
    "\n",
    "## Step 1 : Iterate through the input files, discarding lines with fewer than 10 movies. Generate a actor to movies mapping, and a reverse movies to actor mapping\n",
    "\n",
    "The lines are cleaned by:\n",
    "- Removing unprintable characters\n",
    "- Removing stuff in brackets () or {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "A = {}\n",
    "M = {}\n",
    "\n",
    "lc = {\"data/actress_movies.txt\" : 1182813, \"data/actor_movies.txt\" : 2167653}\n",
    "\n",
    "printable = set(string.printable)\n",
    "\n",
    "def clean_string(s):\n",
    "    return(re.sub(r'\\(.*\\)|\\{.*\\}|\\'|\\\"', \"\", s).lstrip().rstrip())\n",
    "\n",
    "for fname in [\"data/actor_movies.txt\", \"data/actress_movies.txt\"]:\n",
    "    with open(fname, \"r\") as f:\n",
    "        for line in timer(f, total = lc[fname], desc=fname.split(\"/\")[1]):\n",
    "            if line.count('\\t\\t') < 10:\n",
    "                pass\n",
    "            else:\n",
    "                line = filter(lambda x : x in printable, line.decode('latin1')).encode('ascii')\n",
    "                splits = line.split(\"\\t\\t\")\n",
    "                actor_name = splits[0]\n",
    "                movies = set(map(clean_string, splits[1:]))\n",
    "                \n",
    "                if actor_name in A:\n",
    "                    A[actor_name] = A[actor_name].union(movies)\n",
    "                else:\n",
    "                    A[actor_name] = movies\n",
    "\n",
    "                for movie in movies:\n",
    "                    if movie not in M:\n",
    "                        M[movie] = [actor_name]\n",
    "                    else:\n",
    "                        M[movie].append(actor_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next find movies with less than 10 actors and drop these movies. This could easily be a cyclic process, so we STOP here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for (m, alist) in M.iteritems():\n",
    "    if len(alist) <= 10 or m == '':\n",
    "        for actor in alist:\n",
    "            A[actor].remove(m)\n",
    "\n",
    "A = {actor : set(filter(lambda x : x in M, movies)) for (actor, movies) in A.iteritems() if len(movies) > 10}\n",
    "M = {m : filter(lambda x : x in A, alist) for (m, alist) in M.iteritems() if len(alist) >= 10}\n",
    "del M['']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57121"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(A.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105216"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(M.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a map from vertices to numbers (to speed up the edge creation process)\n",
    "vmap = {actor : i for (i, actor) in enumerate(A.keys())}\n",
    "\n",
    "for (i, actor) in enumerate(A.keys()):\n",
    "    vmap[i] = actor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Generate a graph from the actor data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import igraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with open('elist.txt', 'w') as f:\n",
    "    for a in timer(A.keys(), desc=\"Edgelist\"):\n",
    "        edges = set()\n",
    "        for movie in A[a]:\n",
    "            for b in M[movie]:\n",
    "                edges.add(vmap[b])\n",
    "        \n",
    "        u = vmap[a]\n",
    "        for v in sorted(edges):\n",
    "            f.write(\"%d %d\\n\" % (u, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = igraph.read(\"elist.txt\", format=\"edgelist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for (i,V) in enumerate(g.vs):\n",
    "    V[\"name\"] = vmap[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Weights\n",
    "for e in timer(g.es, total=g.ecount(), desc=\"Weights\"):\n",
    "    u = vmap[e.source]\n",
    "    v = vmap[e.target]\n",
    "    e[\"weight\"] = float( len( A[u].intersection(A[v]) ) ) / len( A[u] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = g.personalized_pagerank(weights=g.es[\"weight\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flowers, Bess 0.000472505463301 806\n",
      "Harris, Sam (II) 0.000387865005965 597\n",
      "Miller, Harold (I) 0.000340242839069 540\n",
      "Phelps, Lee (I) 0.000324947231728 627\n",
      "O'Connor, Frank (I) 0.000291386463035 601\n",
      "Farnum, Franklyn 0.000286517084469 500\n",
      "Steers, Larry 0.00027674253104 504\n",
      "Sullivan, Charles (I) 0.00027489830587 496\n",
      "Sayre, Jeffrey 0.000268062042728 427\n",
      "Holmes, Stuart (I) 0.00025927339796 436\n"
     ]
    }
   ],
   "source": [
    "# TOP 10 in PageRank\n",
    "for i in np.argsort(res)[::-1][:10]:\n",
    "    print g.vs[i][\"name\"], res[i], len(A[g.vs[i][\"name\"]])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "widgets": {
   "state": {
    "1245ce2dcd7a40a99a9b58b932c498d6": {
     "views": [
      {
       "cell_index": 2
      }
     ]
    },
    "138a658ec6b24597bc80f6fa3215d659": {
     "views": [
      {
       "cell_index": 2
      }
     ]
    },
    "3a47380eb6904ee69049b0a1d9a1a442": {
     "views": [
      {
       "cell_index": 2
      }
     ]
    },
    "5465af831fb740659c552ce118dc61ae": {
     "views": [
      {
       "cell_index": 2
      }
     ]
    },
    "65f54bfaabc94173b33bf5c6f7ed9a87": {
     "views": [
      {
       "cell_index": 2
      }
     ]
    },
    "671a92199e9645bc8b34a9d1fefc183c": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    },
    "76f4fbe7fc3a427bb79942ae04344290": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "ac29d329ae8b4259aeedb66c90f85781": {
     "views": [
      {
       "cell_index": 3
      }
     ]
    },
    "b597da482eaa4a3fa70fff2690adacfc": {
     "views": [
      {
       "cell_index": 3
      }
     ]
    },
    "b631c53e5cc54f739e79e696307e6058": {
     "views": [
      {
       "cell_index": 2
      }
     ]
    },
    "bc79f3d1164d4ebdad01f1049fb2438c": {
     "views": [
      {
       "cell_index": 2
      }
     ]
    },
    "bee42369345f4f0897f6bfb11f32e01f": {
     "views": [
      {
       "cell_index": 2
      }
     ]
    },
    "ddcd036b5f2c40b1b33e078a57ab68f6": {
     "views": [
      {
       "cell_index": 2
      }
     ]
    },
    "e9bfbee0363e4b5b88828d4bf4155f80": {
     "views": [
      {
       "cell_index": 2
      }
     ]
    },
    "f8df1e2a809244c6b7fe5fe673f64422": {
     "views": [
      {
       "cell_index": 2
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
